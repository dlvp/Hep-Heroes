{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code read the HEP and HepNames xml files that can be found here: http://inspirehep.net/dumps/inspire-dump.html .\n",
    "Various tags are read and saved into two json files 'INSPIREjson' (from HEP) and 'HEPNAMESjson' (from HepNames). In this code I save more tags than those that are actually needed. A reduced version of HEPNAMESjson and INSPIREjson, Can be found in this same repository. The markup record for the xml can be found here https://twiki.cern.ch/twiki/bin/view/Inspire/DevelopmentRecordMarkup ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read HEP </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file to read is called 'HEP-records.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_record(record):\n",
    "    with open('inspire_0', 'a') as f:\n",
    "        json.dump(record, f)\n",
    "        f.write(os.linesep)\n",
    "\n",
    "    \n",
    "def process_buffer_big(buf):\n",
    "    flag=1\n",
    "    tnode = ET.fromstring(buf)\n",
    "    vec=[i for i in range(25)]\n",
    "    vec[0]=tnode.findall(\"./controlfield[@tag='001']\")\n",
    "    vec[1]=tnode.findall(\"./datafield[@tag='035']/subfield[@code='a']\")\n",
    "    vec[2]=tnode.findall(\"./datafield[@tag='035']/subfield[@code='9']\")\n",
    "    vec[3]=tnode.findall(\"./datafield[@tag='037']/subfield[@code='9']\")\n",
    "    vec[4]=tnode.findall(\"./datafield[@tag='037']/subfield[@code='a']\")\n",
    "    vec[5]=tnode.findall(\"./datafield[@tag='037']/subfield[@code='c']\")\n",
    "    vec[6]=tnode.findall(\"./datafield[@tag='100']/subfield[@code='a']\")\n",
    "    vec[7]=tnode.findall(\"./datafield[@tag='100']/subfield[@code='x']\")\n",
    "    vec[8]=tnode.findall(\"./datafield[@tag='700']/subfield[@code='a']\")\n",
    "    vec[9]=tnode.findall(\"./datafield[@tag='700']/subfield[@code='x']\")\n",
    "    vec[10]=tnode.findall(\"./datafield[@tag='245']/subfield[@code='a']\")\n",
    "    vec[11]=tnode.findall(\"./datafield[@tag='269']/subfield[@code='c']\")\n",
    "    vec[12]=tnode.findall(\"./datafield[@tag='961']/subfield[@code='x']\")\n",
    "    vec[13]=tnode.findall(\"./datafield[@tag='961']/subfield[@code='c']\")\n",
    "    vec[14]=tnode.findall(\"./datafield[@tag='650'][@ind1='1'][@ind2='7']/subfield[@code='a']\")\n",
    "    vec[15]=tnode.findall(\"./datafield[@tag='693']/subfield[@code='0']\")\n",
    "    vec[16]=tnode.findall(\"./datafield[@tag='693']/subfield[@code='a']\")\n",
    "    vec[17]=tnode.findall(\"./datafield[@tag='693']/subfield[@code='e']\")\n",
    "    vec[18]=tnode.findall(\"./datafield[@tag='710']/subfield[@code='0']\")\n",
    "    vec[19]=tnode.findall(\"./datafield[@tag='710']/subfield[@code='g']\")\n",
    "    vec[20]=tnode.findall(\"./datafield[@tag='999'][@ind1='C'][@ind2='5']/subfield[@code='0']\")\n",
    "    vec[21]=tnode.findall(\"./datafield[@tag='999'][@ind1='C'][@ind2='5']/subfield[@code='1']\")\n",
    "    vec[22]=tnode.findall(\"./datafield[@tag='999'][@ind1='C'][@ind2='5']/subfield[@code='2']\")\n",
    "    vec[23]=tnode.findall(\"./datafield[@tag='999'][@ind1='C'][@ind2='5']/subfield[@code='r']\")\n",
    "    vec[24]=tnode.findall(\"./datafield[@tag='100']/subfield[@code='w']\")\n",
    "\n",
    "    for i in range(len(vec)):\n",
    "        vec[i]=[vec[i][j].text for j in range(len(vec[i]))]\n",
    "    my_dict = {'item':vec[0], 'key1':vec[1], 'key2':vec[2], 'cat0':vec[3], 'cat1':vec[4], 'cat2':vec[5],\\\n",
    "               'aut1N':vec[6], 'aut1ID':vec[7], 'autN':vec[8], 'autID':vec[9], 'title':vec[10],\\\n",
    "               'date0':vec[11], 'date1':vec[12], 'date2':vec[13], 'content':vec[14], 'exp0':vec[15], 'exp1':vec[16], \\\n",
    "               'exp2':vec[17], 'coll0':vec[18], 'coll1':vec[19], \\\n",
    "               'cit0':vec[20], 'cit1':vec[21], 'cit2':vec[22], 'cit3':vec[23],'aut1BAI':vec[23]}\n",
    "    append_record(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "inputbuffer = ''\n",
    "with open('HEP-records.xml','rb') as inputfile:\n",
    "    append = False\n",
    "    for line in inputfile:\n",
    "        if '<record>' in line:\n",
    "            inputbuffer = line\n",
    "            append = True\n",
    "        elif '</record>'in line:\n",
    "            inputbuffer += line\n",
    "            append = False\n",
    "            process_buffer_big(inputbuffer)\n",
    "            count+=1\n",
    "            if count%10000==0:\n",
    "                print count\n",
    "            inputbuffer = None\n",
    "        elif append:\n",
    "            inputbuffer += line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the file as a json and save it as a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('inspire_0') as f:\n",
    "    my_list = [json.loads(line) for line in f]\n",
    "    \n",
    "with open('inspire_big.json', 'w') as f:\n",
    "    json.dump(my_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read HepNames </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file to read is called 'HepNames-records.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_record(record):\n",
    "    with open('hepnames_0', 'a') as f:\n",
    "        json.dump(record, f)\n",
    "        f.write(os.linesep)\n",
    "\n",
    "\n",
    "def process_buffer_big(buf):\n",
    "    tnode = ET.fromstring(buf)\n",
    "    vec=[i for i in range(7)]\n",
    "    vec[0]=tnode.findall(\"./controlfield[@tag='001']\")\n",
    "    vec[1]=tnode.findall(\"./datafield[@tag='035']/subfield[@code='a']\")\n",
    "    vec[2]=tnode.findall(\"./datafield[@tag='035']/subfield[@code='9']\")\n",
    "    vec[3]=tnode.findall(\"./datafield[@tag='100']/subfield[@code='a']\")\n",
    "    vec[4]=tnode.findall(\"./datafield[@tag='100']/subfield[@code='q']\")\n",
    "    vec[5]=tnode.findall(\"./datafield[@tag='961']/subfield[@code='x']\")\n",
    "    vec[6]=tnode.findall(\"./datafield[@tag='961']/subfield[@code='c']\")\n",
    "    for i in range(len(vec)):\n",
    "        vec[i]=[vec[i][j].text for j in range(len(vec[i]))]\n",
    "    my_dict = {'item':vec[0], 'key1':vec[1], 'key2':vec[2], 'autN':vec[3], 'autID':vec[4], 'date1':vec[5],\\\n",
    "               'date2':vec[6]}\n",
    "    append_record(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "inputbuffer = ''\n",
    "with open('HepNames-records.xml','rb') as inputfile:\n",
    "    append = False\n",
    "    for line in inputfile:\n",
    "        if '<record>' in line:\n",
    "            inputbuffer = line\n",
    "            append = True\n",
    "        elif '</record>'in line:\n",
    "            inputbuffer += line\n",
    "            append = False\n",
    "            process_buffer_big(inputbuffer)\n",
    "            count+=1\n",
    "            if count%10000==0:\n",
    "                print count\n",
    "            inputbuffer = None\n",
    "        elif append:\n",
    "            inputbuffer += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('hepnames_0') as f:\n",
    "    my_list = [json.loads(line) for line in f]\n",
    "\n",
    "with open('hepnames.json', 'w') as f:\n",
    "    json.dump(my_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
